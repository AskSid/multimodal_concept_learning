## SLURM PROLOG ###############################################################
##    Job ID : 13539810
##  Job Name : token_analysis
##  Nodelist : gpu2003
##      CPUs : 
##  Mem/Node : 16384 MB
## Directory : /oscar/data/epavlick/sboppana/multimodal_concept_learning
##   Job Started : Fri Oct 24 11:50:14 AM EDT 2025
###############################################################################
Loading embeddings from: /users/sboppana/data/sboppana/multimodal_concept_learning/results/multimodal/color/96_colors_375
Saving plots to: /users/sboppana/data/sboppana/multimodal_concept_learning/results/multimodal/color/96_colors_375/token_analysis
Loaded saved tokenizer with vocabulary size: 262235
Loaded initial model embeddings: torch.Size([262235, 1152])
Loaded epoch 0 embeddings: torch.Size([262235, 1152])
Loaded epoch 1 embeddings: torch.Size([262235, 1152])
Loaded epoch 2 embeddings: torch.Size([262235, 1152])
Loaded epoch 3 embeddings: torch.Size([262235, 1152])
Loaded epoch 4 embeddings: torch.Size([262235, 1152])
Loaded epoch 5 embeddings: torch.Size([262235, 1152])
Loaded epoch 6 embeddings: torch.Size([262235, 1152])
Total loaded 8 embedding matrices
Found 90 OOD tokens and 6 regular tokens in labels mapping
OOD tokens: ['<ood 1>', '<ood 2>', '<ood 3>', '<ood 4>', '<ood 5>', '<ood 6>', '<ood 7>', '<ood 8>', '<ood 9>', '<ood 10>', '<ood 11>', '<ood 12>', '<ood 13>', '<ood 14>', '<ood 15>', '<ood 16>', '<ood 17>', '<ood 18>', '<ood 19>', '<ood 20>', '<ood 21>', '<ood 22>', '<ood 23>', '<ood 24>', '<ood 25>', '<ood 26>', '<ood 27>', '<ood 28>', '<ood 29>', '<ood 30>', '<ood 31>', '<ood 32>', '<ood 33>', '<ood 34>', '<ood 35>', '<ood 36>', '<ood 37>', '<ood 38>', '<ood 39>', '<ood 40>', '<ood 41>', '<ood 42>', '<ood 43>', '<ood 44>', '<ood 45>', '<ood 46>', '<ood 47>', '<ood 48>', '<ood 49>', '<ood 50>', '<ood 51>', '<ood 52>', '<ood 53>', '<ood 54>', '<ood 55>', '<ood 56>', '<ood 57>', '<ood 58>', '<ood 59>', '<ood 60>', '<ood 61>', '<ood 62>', '<ood 63>', '<ood 64>', '<ood 65>', '<ood 66>', '<ood 67>', '<ood 68>', '<ood 69>', '<ood 70>', '<ood 71>', '<ood 72>', '<ood 73>', '<ood 74>', '<ood 75>', '<ood 76>', '<ood 77>', '<ood 78>', '<ood 79>', '<ood 80>', '<ood 81>', '<ood 82>', '<ood 83>', '<ood 84>', '<ood 85>', '<ood 86>', '<ood 87>', '<ood 88>', '<ood 89>', '<ood 90>']
Tokenizer vocabulary size: 262235
Regular tokens: 6
OOD tokens: 90

=== Token Analysis ===
Total vocabulary size: 262235
Regular tokens: 6
OOD tokens: 90

Sample regular tokens: ['red', 'green', 'blue', 'yellow', 'magenta']

Sample OOD tokens: ['<ood 1>', '<ood 2>', '<ood 3>', '<ood 4>', '<ood 5>']

OOD token IDs: [262145, 262146, 262147, 262148, 262149, 262150, 262151, 262152, 262153, 262154, 262155, 262156, 262157, 262158, 262159, 262160, 262161, 262162, 262163, 262164, 262165, 262166, 262167, 262168, 262169, 262170, 262171, 262172, 262173, 262174, 262175, 262176, 262177, 262178, 262179, 262180, 262181, 262182, 262183, 262184, 262185, 262186, 262187, 262188, 262189, 262190, 262191, 262192, 262193, 262194, 262195, 262196, 262197, 262198, 262199, 262200, 262201, 262202, 262203, 262204, 262205, 262206, 262207, 262208, 262209, 262210, 262211, 262212, 262213, 262214, 262215, 262216, 262217, 262218, 262219, 262220, 262221, 262222, 262223, 262224, 262225, 262226, 262227, 262228, 262229, 262230, 262231, 262232, 262233, 262234]
Regular token IDs: [1192, 10671, 9503, 23861, 96984, 57182]...
Analyzing 96 tokens across 8 epochs
initial: (96, 1152)
epoch_0: (96, 1152)
epoch_1: (96, 1152)
epoch_2: (96, 1152)
epoch_3: (96, 1152)
epoch_4: (96, 1152)
epoch_5: (96, 1152)
epoch_6: (96, 1152)

Applying PCA downscaling to 32 dimensions...
PCA transformed initial: (96, 32)
PCA transformed epoch_0: (96, 32)
PCA transformed epoch_1: (96, 32)
PCA transformed epoch_2: (96, 32)
PCA transformed epoch_3: (96, 32)
PCA transformed epoch_4: (96, 32)
PCA transformed epoch_5: (96, 32)
PCA transformed epoch_6: (96, 32)

Fitting UMAP on PCA-reduced initial embeddings...
Transformed initial: (96, 2)
Transformed epoch_0: (96, 2)
Transformed epoch_1: (96, 2)
Transformed epoch_2: (96, 2)
Transformed epoch_3: (96, 2)
Transformed epoch_4: (96, 2)
Transformed epoch_5: (96, 2)
Transformed epoch_6: (96, 2)
Extracted RGB colors for 96 tokens
Saved UMAP plot to /users/sboppana/data/sboppana/multimodal_concept_learning/results/multimodal/color/96_colors_375/token_analysis/token_embeddings_umap.png

=== RGB Color Information ===
Regular tokens:
  red: RGB(1.000, 0.000, 0.000)
  green: RGB(0.000, 1.000, 0.000)
  blue: RGB(0.000, 0.000, 1.000)
  yellow: RGB(1.000, 1.000, 0.000)
  magenta: RGB(1.000, 0.000, 1.000)
  cyan: RGB(0.000, 1.000, 1.000)

OOD tokens (first 5):
  <ood 1>: RGB(1.000, 0.125, 0.000)
  <ood 2>: RGB(1.000, 0.000, 0.125)
  <ood 3>: RGB(0.125, 1.000, 0.000)
  <ood 4>: RGB(0.000, 1.000, 0.125)
  <ood 5>: RGB(0.125, 0.000, 1.000)
  ... and 85 more OOD tokens
=== Creating 3D UMAP Visualization ===
Using epoch_6 for 3D visualization
Token embeddings shape: (96, 1152)
Applying PCA downscaling to 32 dimensions for 3D UMAP...
PCA transformed embeddings shape: (96, 32)
Fitting 3D UMAP...
3D projections shape: (96, 3)
Saved 3D UMAP plot to /users/sboppana/data/sboppana/multimodal_concept_learning/results/multimodal/color/96_colors_375/token_analysis/token_embeddings_3d_umap.html
3D UMAP visualization complete!
=== Regular Tokens UMAP Analysis ===
initial: (6, 1152)
epoch_0: (6, 1152)
epoch_1: (6, 1152)
epoch_2: (6, 1152)
epoch_3: (6, 1152)
epoch_4: (6, 1152)
epoch_5: (6, 1152)
epoch_6: (6, 1152)

Applying PCA downscaling to 32 dimensions for regular tokens...
Token embedding analysis completed at Fri Oct 24 11:52:12 AM EDT 2025
